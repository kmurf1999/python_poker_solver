from best_response import BestResponsePolicy

    # def _state_values(self, state) -> (float, float):
    #     """get value of playing on strategy"""
    #     if state.is_terminal:
    #         return state.get_utility()
    #     if state.is_chance:
    #         chances = state.legal_actions
    #         prob = 1 / len(chances)
    #         return sum(prob * self._state_values(state.apply(chance))
    #                 for chance in chances)
    #     else:
    #         actions = state.legal_actions
    #         probs = self._trainer.get_or_create(
    #                 state.infoset_str(state.current), len(actions)).get_final_strategy()
    #         return sum(probs[i] * self._state_values(state.apply(actions[i]))
    #                 for i in range(len(actions)))

def exploitability(trainer):
    """Returns exploitability of cfr trainer strategy"""
    nash_conv = sum(
            BestResponsePolicy(i, trainer).value(
                trainer._initial_state) for i in [0, 1])
    return nash_conv / 2 # num players


